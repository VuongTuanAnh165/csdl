# train_model.py
# ‚úÖ Hu·∫•n luy·ªán m√¥ h√¨nh XGBoost ph√¢n lo·∫°i truy v·∫•n SQL nhanh/ch·∫≠m t·ª´ log ƒë√£ khai ph√°

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
import xgboost as xgb
import matplotlib.pyplot as plt
import joblib
import os
import sys

# ==== 1. ƒê·ªçc d·ªØ li·ªáu log t·ª´ file ====
log_path = "query_log.csv"
if not os.path.exists(log_path):
    print("‚ùå Kh√¥ng t√¨m th·∫•y file query_log.csv. H√£y ch·∫°y log_queries.py tr∆∞·ªõc.")
    sys.exit(1)

df = pd.read_csv(log_path)
df = df[df['status'] == 'OK'].copy()  # L·ªçc b·ªè truy v·∫•n l·ªói

# ==== 2. Lo·∫°i b·ªè truy v·∫•n d·ªã bi·ªát (outliers) ====
q95 = df["exec_time_sec"].quantile(0.95)
df = df[df["exec_time_sec"] <= q95]
print(f"‚úÖ ƒê√£ lo·∫°i b·ªè c√°c truy v·∫•n c√≥ exec_time_sec > {q95:.2f}s (top 5%)")

# ==== 3. Ki·ªÉm tra nh√£n m·ª•c ti√™u ====
if 'is_slow' not in df.columns or df['is_slow'].nunique() < 2:
    print("‚ö†Ô∏è C·∫ßn c·∫£ truy v·∫•n nhanh v√† ch·∫≠m. H√£y ki·ªÉm tra l·∫°i log.")
    sys.exit(1)

print("\nüìä Ph√¢n ph·ªëi nh√£n m·ª•c ti√™u (is_slow):")
print(df['is_slow'].value_counts(normalize=True))

# ==== 4. X·ª≠ l√Ω ƒë·∫∑c tr∆∞ng syntax (has_...) ====
syntax_cols = ['has_like', 'has_group', 'has_join', 'has_order', 'has_limit', 'has_distinct']
for col in syntax_cols:
    if col not in df.columns:
        df[col] = 0  # N·∫øu thi·∫øu c·ªôt, g√°n m·∫∑c ƒë·ªãnh 0

# ==== 5. One-hot encoding cho c·ªôt 'types' ====
if 'types' in df.columns:
    types_dummies = df['types'].str.get_dummies(sep=',')
else:
    types_dummies = pd.DataFrame()
    print("‚ö†Ô∏è C·ªôt 'types' kh√¥ng c√≥ trong d·ªØ li·ªáu. B·ªè qua one-hot.")

# ==== 6. K·∫øt h·ª£p ƒë·∫∑c tr∆∞ng ƒë·∫ßu v√†o ====
base_features = ['rows_examined', 'uses_index', 'num_tables'] + syntax_cols
X = pd.concat([df[base_features], types_dummies], axis=1)
y = df['is_slow']

# ==== 7. T√°ch d·ªØ li·ªáu train/test ====
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

# ==== 8. Hu·∫•n luy·ªán m√¥ h√¨nh XGBoost ====
model = xgb.XGBClassifier(
    objective="binary:logistic",
    eval_metric="logloss",
    max_depth=5,
    n_estimators=100,
    learning_rate=0.1,
    random_state=42,
    use_label_encoder=False
)
model.fit(X_train, y_train)

# ==== 9. ƒê√°nh gi√° m√¥ h√¨nh ====
from sklearn.metrics import accuracy_score, f1_score

y_pred = model.predict(X_test)
acc = accuracy_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print("\n=== [Confusion Matrix] ===")
print(confusion_matrix(y_test, y_pred))
print("\n=== [Classification Report] ===")
print(classification_report(y_test, y_pred))
print(f"\n‚úÖ Accuracy: {acc:.4f} | F1-score: {f1:.4f}")

# ==== 10. L∆∞u m√¥ h√¨nh v√† th√¥ng tin li√™n quan ====
joblib.dump(model, "slow_query_model.pkl")
joblib.dump(X.columns.tolist(), "model_features.pkl")
print("‚úÖ ƒê√£ l∆∞u m√¥ h√¨nh v√†o slow_query_model.pkl")
print("‚úÖ ƒê√£ l∆∞u ƒë·∫∑c tr∆∞ng ƒë·∫ßu v√†o v√†o model_features.pkl")

# === 11. L∆∞u h√¨nh ·∫£nh + bi·ªÉu ƒë·ªì ===
os.makedirs("figures", exist_ok=True)

plt.figure(figsize=(10, 6))
xgb.plot_importance(model, height=0.5, importance_type='gain', show_values=False)
plt.title("T·∫ßm quan tr·ªçng c·ªßa c√°c ƒë·∫∑c tr∆∞ng")
plt.tight_layout()
plt.savefig("figures/feature_importance.png")
plt.close()
print("‚úÖ ƒê√£ l∆∞u bi·ªÉu ƒë·ªì t·∫ßm quan tr·ªçng v√†o figures/feature_importance.png")

# === 12. L∆∞u k·∫øt qu·∫£ test v√†o file CSV ===
df_test = X_test.copy()
df_test["y_true"] = y_test.values
df_test["y_pred"] = y_pred
df_test.to_csv("figures/model_test_result.csv", index=False)
print("üìù ƒê√£ l∆∞u k·∫øt qu·∫£ d·ª± ƒëo√°n test v√†o figures/model_test_result.csv")

# === 13. L∆∞u log ƒë·ªô ch√≠nh x√°c v√†o file (n·∫øu c·∫ßn d√πng cho b√°o c√°o) ===
with open("figures/metrics.txt", "w") as f:
    f.write(f"Accuracy: {acc:.4f}\n")
    f.write(f"F1-score: {f1:.4f}\n")
print("üìù ƒê√£ l∆∞u ch·ªâ s·ªë ƒë√°nh gi√° v√†o figures/metrics.txt")

# T·∫°o th∆∞ m·ª•c l∆∞u h√¨nh ·∫£nh n·∫øu ch∆∞a c√≥
os.makedirs("figures", exist_ok=True)

# L∆∞u bi·ªÉu ƒë·ªì t·∫ßm quan tr·ªçng ƒë·∫∑c tr∆∞ng
plt.figure(figsize=(10, 6))
xgb.plot_importance(model, height=0.5, importance_type='gain', show_values=False)
plt.title("T·∫ßm quan tr·ªçng c·ªßa c√°c ƒë·∫∑c tr∆∞ng")
plt.tight_layout()
plt.savefig("figures/feature_importance.png")
plt.close()
print("‚úÖ ƒê√£ l∆∞u bi·ªÉu ƒë·ªì t·∫ßm quan tr·ªçng v√†o figures/feature_importance.png")
