# train_model.py
# ‚úÖ Hu·∫•n luy·ªán m√¥ h√¨nh XGBoost ph√¢n lo·∫°i truy v·∫•n SQL nhanh/ch·∫≠m t·ª´ log ƒë√£ khai ph√°

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, ConfusionMatrixDisplay
import xgboost as xgb
import matplotlib.pyplot as plt
import joblib
import os
import sys

# ==== 1. ƒê·ªçc d·ªØ li·ªáu log t·ª´ file ====
log_path = "query_log.csv"
if not os.path.exists(log_path):
    print("‚ùå Kh√¥ng t√¨m th·∫•y file query_log.csv. H√£y ch·∫°y log_queries.py tr∆∞·ªõc.")
    sys.exit(1)

df = pd.read_csv(log_path)
df = df[df['status'] == 'OK'].copy()  # L·ªçc b·ªè truy v·∫•n l·ªói

# ==== 2. Lo·∫°i b·ªè truy v·∫•n d·ªã bi·ªát (outliers) ====
q95 = df["exec_time_sec"].quantile(0.95)
df = df[df["exec_time_sec"] <= q95]
print(f"‚úÖ ƒê√£ lo·∫°i b·ªè c√°c truy v·∫•n c√≥ exec_time_sec > {q95:.2f}s (top 5%)")

# ==== 3. Ki·ªÉm tra nh√£n m·ª•c ti√™u ====
if 'is_slow' not in df.columns or df['is_slow'].nunique() < 2:
    print("‚ö†Ô∏è C·∫ßn c·∫£ truy v·∫•n nhanh v√† ch·∫≠m. H√£y ki·ªÉm tra l·∫°i log.")
    sys.exit(1)

print("\nüìä Ph√¢n ph·ªëi nh√£n m·ª•c ti√™u (is_slow):")
print(df['is_slow'].value_counts(normalize=True))

# ==== 4. X·ª≠ l√Ω ƒë·∫∑c tr∆∞ng syntax (has_...) ====
syntax_cols = ['has_like', 'has_group', 'has_join', 'has_order', 'has_limit', 'has_distinct']
for col in syntax_cols:
    if col not in df.columns:
        df[col] = 0  # N·∫øu thi·∫øu c·ªôt, g√°n m·∫∑c ƒë·ªãnh 0

# ==== 5. One-hot encoding cho c·ªôt 'types' ====
if 'types' in df.columns:
    types_dummies = df['types'].str.get_dummies(sep=',')
else:
    types_dummies = pd.DataFrame()
    print("‚ö†Ô∏è C·ªôt 'types' kh√¥ng c√≥ trong d·ªØ li·ªáu. B·ªè qua one-hot.")

# ==== 6. K·∫øt h·ª£p ƒë·∫∑c tr∆∞ng ƒë·∫ßu v√†o ====
base_features = ['rows_examined', 'uses_index', 'num_tables'] + syntax_cols
X = pd.concat([df[base_features], types_dummies], axis=1)
y = df['is_slow']

# ==== 7. T√°ch d·ªØ li·ªáu train/test ====
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

# ==== 8. Hu·∫•n luy·ªán m√¥ h√¨nh XGBoost ====
eval_set = [(X_train, y_train), (X_test, y_test)]

model = xgb.XGBClassifier(
    objective="binary:logistic",
    eval_metric="logloss",
    max_depth=5,
    n_estimators=100,
    learning_rate=0.1,
    random_state=42,
    use_label_encoder=False
)

model.fit(
    X_train, y_train,
    eval_set=eval_set,
    verbose=False
)

# ==== 9. ƒê√°nh gi√° m√¥ h√¨nh ====
y_pred = model.predict(X_test)
acc = accuracy_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print("\n=== [Confusion Matrix] ===")
print(confusion_matrix(y_test, y_pred))
print("\n=== [Classification Report] ===")
print(classification_report(y_test, y_pred))
print(f"\n‚úÖ Accuracy: {acc:.4f} | F1-score: {f1:.4f}")

# T·∫°o th∆∞ m·ª•c l∆∞u h√¨nh ·∫£nh n·∫øu ch∆∞a c√≥
os.makedirs("figures", exist_ok=True)

# ==== 9b. V·∫Ω confusion matrix ====
plt.figure(figsize=(5, 4))
disp = ConfusionMatrixDisplay(confusion_matrix(y_test, y_pred), display_labels=["Nhanh (0)", "Ch·∫≠m (1)"])
disp.plot(cmap="Blues", values_format="d")
plt.title("Confusion Matrix - D·ª± ƒëo√°n truy v·∫•n nhanh/ch·∫≠m")
plt.tight_layout()
plt.savefig("figures/confusion_matrix.png")
plt.close()
print("‚úÖ ƒê√£ l∆∞u confusion matrix v√†o figures/confusion_matrix.png")

# ==== 9c. L∆∞u classification report d·∫°ng b·∫£ng CSV ====
report = classification_report(y_test, y_pred, output_dict=True)
report_df = pd.DataFrame(report).transpose()
report_df.to_csv("figures/classification_report.csv")
print("üìù ƒê√£ l∆∞u classification report d·∫°ng b·∫£ng t·∫°i figures/classification_report.csv")

# ==== 10. L∆∞u m√¥ h√¨nh v√† th√¥ng tin li√™n quan ====
joblib.dump(model, "slow_query_model.pkl")
joblib.dump(X.columns.tolist(), "model_features.pkl")
print("‚úÖ ƒê√£ l∆∞u m√¥ h√¨nh v√†o slow_query_model.pkl")
print("‚úÖ ƒê√£ l∆∞u ƒë·∫∑c tr∆∞ng ƒë·∫ßu v√†o v√†o model_features.pkl")

# === 11. L∆∞u bi·ªÉu ƒë·ªì t·∫ßm quan tr·ªçng ƒë·∫∑c tr∆∞ng ===
for imp_type in ["weight", "gain", "cover"]:
    plt.figure(figsize=(10, 6))
    xgb.plot_importance(model, importance_type=imp_type, height=0.5, show_values=False)
    plt.title(f"T·∫ßm quan tr·ªçng c·ªßa ƒë·∫∑c tr∆∞ng ({imp_type})")
    plt.tight_layout()
    plt.savefig(f"figures/feature_importance_{imp_type}.png")
    plt.close()
    print(f"‚úÖ ƒê√£ l∆∞u feature importance ({imp_type}) v√†o figures/feature_importance_{imp_type}.png")

# ==== 11c. Learning curve ====
results = model.evals_result()
plt.figure(figsize=(8, 5))
plt.plot(results["validation_0"]["logloss"], label="Train logloss")
plt.plot(results["validation_1"]["logloss"], label="Test logloss")
plt.xlabel("Iterations")
plt.ylabel("Logloss")
plt.title("Learning curve")
plt.legend()
plt.tight_layout()
plt.savefig("figures/learning_curve.png")
plt.close()
print("‚úÖ ƒê√£ l∆∞u learning curve v√†o figures/learning_curve.png")

# === 12. L∆∞u k·∫øt qu·∫£ test v√†o file CSV ===
df_test = X_test.copy()
df_test["y_true"] = y_test.values
df_test["y_pred"] = y_pred
df_test.to_csv("figures/model_test_result.csv", index=False)
print("üìù ƒê√£ l∆∞u k·∫øt qu·∫£ d·ª± ƒëo√°n test v√†o figures/model_test_result.csv")

# === 13. L∆∞u log ƒë·ªô ch√≠nh x√°c v√†o file (n·∫øu c·∫ßn d√πng cho b√°o c√°o) ===
with open("figures/metrics.txt", "w") as f:
    f.write(f"Accuracy: {acc:.4f}\n")
    f.write(f"F1-score: {f1:.4f}\n")
print("üìù ƒê√£ l∆∞u ch·ªâ s·ªë ƒë√°nh gi√° v√†o figures/metrics.txt")
